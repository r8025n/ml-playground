{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workaround for non rocm supported amd gpus\n",
    "\n",
    "from os import putenv\n",
    "putenv(\"HSA_OVERRIDE_GFX_VERSION\", \"10.3.0\")\n",
    "putenv(\"PYTORCH_ROCM_ARCH\", \"gfx1030\")\n",
    "putenv(\"TORCH_USE_HIP_DSA\", \"1\")\n",
    "putenv(\"AMD_SERIALIZE_KERNEL\", \"3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# os.environ[\"HSA_OVERRIDE_GFX_VERSION\"] = \"10.3.0\"\n",
    "# os.environ[\"TORCH_USE_HIP_DSA\"] = \"1\"\n",
    "# os.environ[\"AMD_SERIALIZE_KERNEL\"] = \"3\"\n",
    "# os.environ[\"HIP_LOG_LEVEL\"] = \"3\"  # Set to debug level\n",
    "# os.environ[\"HIP_VISIBLE_DEVICES\"] = \"0\"  # Ensure only the first GPU is visible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !which python\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"ROCm Available:\", torch.version.hip is not None)\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")\n",
    "print(torch.version.hip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a tensor and move it to the GPU\n",
    "# tensor = torch.randn(3, 3).to('cuda')\n",
    "# print(tensor)\n",
    "\n",
    "# # Check if the tensor is on the GPU\n",
    "# print(tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(x):\n",
    "    plt.figure()\n",
    "    combined_image = np.concatenate((x[0][0].detach().numpy(), x[0][10].detach().numpy(), x[0][-1].detach().numpy()), axis=1)\n",
    "    plt.imshow(combined_image)\n",
    "\n",
    "    return\n",
    "\n",
    "def crop_image(source_tensor, target_tensor):\n",
    "    source_tensor_size = source_tensor.size()[2]\n",
    "    target_tensor_size = target_tensor.size()[2]\n",
    "\n",
    "    start_x = (source_tensor.size()[2] - target_tensor.size()[2]) // 2\n",
    "    start_y = (source_tensor.size()[3] - target_tensor.size()[3]) // 2\n",
    "\n",
    "    return source_tensor[:, :, start_x:start_x + target_tensor.size()[2], start_y:start_y + target_tensor.size()[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_conv(in_channel, out_channel):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channel, out_channel, kernel_size=3),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_channel, out_channel, kernel_size=3),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.down_conv1 = double_conv(3, 64)\n",
    "        self.down_conv2 = double_conv(64, 128)\n",
    "        self.down_conv3 = double_conv(128, 256)\n",
    "        self.down_conv4 = double_conv(256, 512)\n",
    "        self.down_conv5 = double_conv(512, 1024)\n",
    "\n",
    "        self.tarnspose_conv_1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.tarnspose_conv_2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.tarnspose_conv_3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.tarnspose_conv_4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.up_conv1 = double_conv(1024, 512)\n",
    "        self.up_conv2 = double_conv(512, 256)\n",
    "        self.up_conv3 = double_conv(256, 128)\n",
    "        self.up_conv4 = double_conv(128, 64)\n",
    "\n",
    "        self.out = nn.Conv2d(64, 1, kernel_size=1)\n",
    "\n",
    "        # self.up_conv1 = double_conv(1024, 512)\n",
    "        # self.up_conv2 = double_conv()\n",
    "\n",
    "    def forward(self, image):\n",
    "        # ////////////// ENCODER //////////////\n",
    "        x1 = self.down_conv1(image)\n",
    "        m1 = self.max_pool(x1)\n",
    "        # plot_img(x)\n",
    "        x2 = self.down_conv2(m1)\n",
    "        m2 = self.max_pool(x2)\n",
    "        # plot_img(x)\n",
    "        x3 = self.down_conv3(m2)\n",
    "        m3 = self.max_pool(x3)\n",
    "        # plot_img(x)\n",
    "        x4 = self.down_conv4(m3)\n",
    "        m4 = self.max_pool(x4)\n",
    "        # plot_img(x)\n",
    "        x5 = self.down_conv5(m4)\n",
    "        # plot_img(x)\n",
    "\n",
    "        # ////////////// DECODER //////////////\n",
    "        x = self.tarnspose_conv_1(x5)\n",
    "        # print(x.shape)\n",
    "        x = self.up_conv1(torch.cat([x, crop_image(x4, x)], 1))\n",
    "        # print(x.shape)\n",
    "        x = self.tarnspose_conv_2(x)\n",
    "        # print(x.shape)\n",
    "        x = self.up_conv2(torch.cat([x, crop_image(x3, x)], 1))\n",
    "        # print(x.shape)\n",
    "        x = self.tarnspose_conv_3(x)\n",
    "        # print(x.shape)\n",
    "        x = self.up_conv3(torch.cat([x, crop_image(x2, x)], 1))\n",
    "        # print(x.shape)\n",
    "        x = self.tarnspose_conv_4(x)\n",
    "        # print(x.shape)\n",
    "        x = self.up_conv4(torch.cat([x, crop_image(x1, x)], 1))\n",
    "        # print(x.shape)\n",
    "        x = self.out(x)\n",
    "\n",
    "        # print(x.shape)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_path = \"./test.png\"\n",
    "# image = Image.open(image_path)\n",
    "# print(type(image))\n",
    "# image = np.array(image)\n",
    "# print(image.size)\n",
    "# image_tensor = torch.from_numpy(image)\n",
    "# plt.imshow(image_tensor)\n",
    "# image_tensor = image_tensor.float()\n",
    "# image_tensor = image_tensor.permute(2, 0, 1)\n",
    "# image_tensor = image_tensor.unsqueeze(0)\n",
    "# print(image_tensor.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = UNet()\n",
    "# output = model(image_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_image = np.concatenate((output[0][0].detach().numpy(), output[0][1].detach().numpy()), axis=1)\n",
    "# print(output.shape)\n",
    "# plt.imshow(output[0][0].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, image_paths, mask_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # image = Image.open(self.image_paths[idx]).convert(\"L\")\n",
    "        # mask = Image.open(self.mask_paths[idx]).convert(\"L\")\n",
    "        image = Image.open(self.image_paths[idx])\n",
    "        mask = Image.open(self.mask_paths[idx])\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "        \n",
    "        return image, mask\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# test_transform = transforms.Compose([\n",
    "#     transforms.Resize((836, 836)),\n",
    "#     transforms.ToTensor()\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "image_dir = \"./original\"\n",
    "mask_dir = \"./mask\"\n",
    "\n",
    "image_paths = sorted(glob(os.path.join(image_dir, '*.[jp][pn]g')))\n",
    "mask_paths = sorted(glob(os.path.join(mask_dir, '*.[jp][pn]g')))\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(image_paths, mask_paths, test_size=0.2, random_state=42)\n",
    "# train_dataset = SegmentationDataset(X_train, y_train, transform=transform)\n",
    "# val_dataset = SegmentationDataset(X_val, y_val, transform=transform)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4, pin_memory=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=2, pin_memory=True)\n",
    "###################################\n",
    "# dataset = datasets.ImageFolder(\"path_to_dataset\", transform=transforms.Compose([\n",
    "#     transforms.Resize((1024, 1024)),  # Adjust size as needed\n",
    "#     transforms.ToTensor(),\n",
    "# ]))\n",
    "\n",
    "# # Define the split proportions\n",
    "# train_size = int(0.80 * len(dataset))\n",
    "# val_size = int(0.10 * len(dataset))\n",
    "# test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "# # Perform the split\n",
    "# train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# # Now create DataLoaders for each set\n",
    "# train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4, pin_memory=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=4, pin_memory=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "#########################################\n",
    "dataset = SegmentationDataset(image_paths, mask_paths, transform=transform)\n",
    "\n",
    "# Split the dataset (80% train, 10% val, 10% test)\n",
    "train_size = int(0.80 * len(dataset))\n",
    "val_size = int(0.10 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, optimizer, criterion, num_epochs=10):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        epoch_loss = 0\n",
    "        model.train()  # Ensure the model is in training mode\n",
    "        for images, masks in train_loader:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            # print(outputs.shape)\n",
    "            # print(masks.shape)\n",
    "            masks_resized = F.interpolate(masks, size=outputs.shape[2:], mode='bilinear', align_corners=False)\n",
    "            masks_resized = masks_resized.mean(dim=1, keepdim=True)\n",
    "            loss = criterion(outputs, masks_resized)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        avg_train_loss = epoch_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss/len(train_loader)}')\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        with torch.no_grad():  # No gradient calculation during validation\n",
    "            val_loss = 0\n",
    "            for images, masks in val_loader:\n",
    "                images = images.to(device)\n",
    "                masks = masks.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                masks_resized = F.interpolate(masks, size=outputs.shape[2:], mode='bilinear', align_corners=False)\n",
    "                masks_resized = masks_resized.mean(dim=1, keepdim=True)\n",
    "                loss = criterion(outputs, masks_resized)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "            avg_val_loss = epoch_loss / len(val_loader)\n",
    "            val_losses.append(avg_val_loss)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss/len(val_loader)}')\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = UNet()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Use GPU if available\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device(\"cpu\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(model, train_loader, val_loader, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model_parameters.pth'))\n",
    "model.eval()  # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test a single image \n",
    "image_path = './test.png'\n",
    "img = Image.open(image_path)\n",
    "plt.figure()\n",
    "plt.imshow(img)\n",
    "img_tensor = transform(img)\n",
    "img_tensor = img_tensor.unsqueeze(0)\n",
    "with torch.no_grad():  # No need to compute gradients during inference\n",
    "    output = model(img_tensor)\n",
    "    output_image = output.squeeze(0) \n",
    "    output_image_np = output_image.permute(1, 2, 0).numpy() \n",
    "    plt.figure()\n",
    "    plt.imshow(output_image_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(preds, targets, epsilon=1e-8):\n",
    "    intersection = (preds * targets).sum(dim=(2, 3))\n",
    "    union = preds.sum(dim=(2, 3)) + targets.sum(dim=(2, 3))\n",
    "    dice = (2. * intersection / (union + epsilon)).mean()\n",
    "    return dice\n",
    "\n",
    "def iou_score(preds, targets, epsilon=1e-8):\n",
    "    intersection = (preds * targets).sum(dim=(2, 3))\n",
    "    union = (preds + targets).sum(dim=(2, 3)) - intersection\n",
    "    iou = (intersection / (union + epsilon)).mean()\n",
    "    return iou\n",
    "\n",
    "def test(model, test_loader, criterion, threshold=0.5):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0\n",
    "    dice_score_total = 0\n",
    "    iou_total = 0\n",
    "    all_outputs = []\n",
    "    all_masks = []\n",
    "\n",
    "    with torch.no_grad():  # No gradient calculation during testing\n",
    "        for images, masks in test_loader:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            masks_resized = F.interpolate(masks, size=outputs.shape[2:], mode='bilinear', align_corners=False)\n",
    "            masks_resized = masks_resized.mean(dim=1, keepdim=True)\n",
    "\n",
    "            loss = criterion(outputs, masks_resized)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Apply a threshold to the outputs to get binary masks\n",
    "            preds = (outputs > threshold).float()\n",
    "\n",
    "            # Calculate Dice coefficient\n",
    "            dice_score = dice_coefficient(preds, masks_resized)\n",
    "            dice_score_total += dice_score.item()\n",
    "\n",
    "            # Calculate IoU\n",
    "            iou = iou_score(preds, masks_resized)\n",
    "            iou_total += iou.item()\n",
    "\n",
    "            # Store outputs and masks (optional)\n",
    "            # all_outputs.append(preds.cpu())\n",
    "            # all_masks.append(masks.cpu())\n",
    "\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    avg_dice_score = dice_score_total / len(test_loader)\n",
    "    avg_iou = iou_total / len(test_loader)\n",
    "\n",
    "    # print(f'Test Loss: {avg_test_loss}')\n",
    "    # print(f'Dice Score: {avg_dice_score}')\n",
    "    # print(f'IoU: {avg_iou}')\n",
    "\n",
    "    return avg_test_loss, avg_dice_score, avg_iou\n",
    "\n",
    "def test_and_visualize(model, test_loader, criterion, threshold=0.5):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0\n",
    "    dice_score_total = 0\n",
    "    iou_total = 0\n",
    "\n",
    "    print_more = True\n",
    "\n",
    "    with torch.no_grad():  # No gradient calculation during testing\n",
    "        for batch_idx, (images, masks) in enumerate(test_loader):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            masks_resized = F.interpolate(masks, size=outputs.shape[2:], mode='bilinear', align_corners=False)\n",
    "            masks_resized = masks_resized.mean(dim=1, keepdim=True)\n",
    "\n",
    "            loss = criterion(outputs, masks_resized)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Apply a threshold to the outputs to get binary masks\n",
    "            preds = (outputs > threshold).float()\n",
    "\n",
    "            # Calculate Dice coefficient and IoU\n",
    "            dice_score = dice_coefficient(preds, masks_resized)\n",
    "            dice_score_total += dice_score.item()\n",
    "\n",
    "            iou = iou_score(preds, masks_resized)\n",
    "            iou_total += iou.item()\n",
    "\n",
    "            # Move data to CPU for visualization\n",
    "            images_cpu = images.cpu()\n",
    "            masks_cpu = masks.cpu()\n",
    "            preds_cpu = preds.cpu()\n",
    "\n",
    "            # Visualize the images, original masks, and predicted masks\n",
    "            if print_more:\n",
    "                print_more = False\n",
    "                for i in range(images_cpu.shape[0]):\n",
    "                    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "                    \n",
    "                    # Plot the original image\n",
    "                    axes[0].imshow(images_cpu[i].permute(1, 2, 0).numpy(), cmap='gray')\n",
    "                    axes[0].set_title('Original Image')\n",
    "                    axes[0].axis('off')\n",
    "\n",
    "                    # Plot the original mask\n",
    "                    axes[1].imshow(masks_cpu[i][0], cmap='gray')  # Assuming masks are in grayscale\n",
    "                    axes[1].set_title('Original Mask')\n",
    "                    axes[1].axis('off')\n",
    "\n",
    "                    # Plot the predicted mask\n",
    "                    axes[2].imshow(preds_cpu[i][0], cmap='gray')  # Predicted mask in grayscale\n",
    "                    axes[2].set_title('Predicted Mask')\n",
    "                    axes[2].axis('off')\n",
    "\n",
    "                    # Show the plots\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    avg_dice_score = dice_score_total / len(test_loader)\n",
    "    avg_iou = iou_total / len(test_loader)\n",
    "\n",
    "    print(f'Test Loss: {avg_test_loss}')\n",
    "    print(f'Dice Score: {avg_dice_score}')\n",
    "    print(f'IoU: {avg_iou}')\n",
    "\n",
    "    return avg_test_loss, avg_dice_score, avg_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, dice_score, iou = test_and_visualize(model, test_loader, criterion)\n",
    "print(f'Final Test Loss: {test_loss}')\n",
    "print(f'Final Dice Score: {dice_score}')\n",
    "print(f'Final IoU: {iou}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import putenv\n",
    "putenv(\"HSA_OVERRIDE_GFX_VERSION\", \"10.3.0\")\n",
    "putenv(\"PYTORCH_ROCM_ARCH\", \"gfx1030\")\n",
    "putenv(\"TORCH_USE_HIP_DSA\", \"1\")\n",
    "putenv(\"AMD_SERIALIZE_KERNEL\", \"3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# os.environ[\"HSA_OVERRIDE_GFX_VERSION\"] = \"10.3.0\"\n",
    "# os.environ[\"TORCH_USE_HIP_DSA\"] = \"1\"\n",
    "# os.environ[\"AMD_SERIALIZE_KERNEL\"] = \"3\"\n",
    "# os.environ[\"HIP_LOG_LEVEL\"] = \"3\"  # Set to debug level\n",
    "# os.environ[\"HIP_VISIBLE_DEVICES\"] = \"0\"  # Ensure only the first GPU is visible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !which python\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "ROCm Available: True\n",
      "GPU Name: AMD Radeon RX 6600\n",
      "6.0.32831-\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"ROCm Available:\", torch.version.hip is not None)\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")\n",
    "print(torch.version.hip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a tensor and move it to the GPU\n",
    "# tensor = torch.randn(3, 3).to('cuda')\n",
    "# print(tensor)\n",
    "\n",
    "# # Check if the tensor is on the GPU\n",
    "# print(tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(x):\n",
    "    plt.figure()\n",
    "    combined_image = np.concatenate((x[0][0].detach().numpy(), x[0][10].detach().numpy(), x[0][-1].detach().numpy()), axis=1)\n",
    "    plt.imshow(combined_image)\n",
    "\n",
    "    return\n",
    "\n",
    "def crop_image(source_tensor, target_tensor):\n",
    "    source_tensor_size = source_tensor.size()[2]\n",
    "    target_tensor_size = target_tensor.size()[2]\n",
    "\n",
    "    start_x = (source_tensor.size()[2] - target_tensor.size()[2]) // 2\n",
    "    start_y = (source_tensor.size()[3] - target_tensor.size()[3]) // 2\n",
    "\n",
    "    return source_tensor[:, :, start_x:start_x + target_tensor.size()[2], start_y:start_y + target_tensor.size()[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_conv(in_channel, out_channel):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channel, out_channel, kernel_size=3),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_channel, out_channel, kernel_size=3),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.down_conv1 = double_conv(3, 64)\n",
    "        self.down_conv2 = double_conv(64, 128)\n",
    "        self.down_conv3 = double_conv(128, 256)\n",
    "        self.down_conv4 = double_conv(256, 512)\n",
    "        self.down_conv5 = double_conv(512, 1024)\n",
    "\n",
    "        self.tarnspose_conv_1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.tarnspose_conv_2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.tarnspose_conv_3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.tarnspose_conv_4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.up_conv1 = double_conv(1024, 512)\n",
    "        self.up_conv2 = double_conv(512, 256)\n",
    "        self.up_conv3 = double_conv(256, 128)\n",
    "        self.up_conv4 = double_conv(128, 64)\n",
    "\n",
    "        self.out = nn.Conv2d(64, 1, kernel_size=1)\n",
    "\n",
    "        # self.up_conv1 = double_conv(1024, 512)\n",
    "        # self.up_conv2 = double_conv()\n",
    "\n",
    "    def forward(self, image):\n",
    "        # ////////////// ENCODER //////////////\n",
    "        x1 = self.down_conv1(image)\n",
    "        m1 = self.max_pool(x1)\n",
    "        # plot_img(x)\n",
    "        x2 = self.down_conv2(m1)\n",
    "        m2 = self.max_pool(x2)\n",
    "        # plot_img(x)\n",
    "        x3 = self.down_conv3(m2)\n",
    "        m3 = self.max_pool(x3)\n",
    "        # plot_img(x)\n",
    "        x4 = self.down_conv4(m3)\n",
    "        m4 = self.max_pool(x4)\n",
    "        # plot_img(x)\n",
    "        x5 = self.down_conv5(m4)\n",
    "        # plot_img(x)\n",
    "\n",
    "        # ////////////// DECODER //////////////\n",
    "        x = self.tarnspose_conv_1(x5)\n",
    "        # print(x.shape)\n",
    "        x = self.up_conv1(torch.cat([x, crop_image(x4, x)], 1))\n",
    "        # print(x.shape)\n",
    "        x = self.tarnspose_conv_2(x)\n",
    "        # print(x.shape)\n",
    "        x = self.up_conv2(torch.cat([x, crop_image(x3, x)], 1))\n",
    "        # print(x.shape)\n",
    "        x = self.tarnspose_conv_3(x)\n",
    "        # print(x.shape)\n",
    "        x = self.up_conv3(torch.cat([x, crop_image(x2, x)], 1))\n",
    "        # print(x.shape)\n",
    "        x = self.tarnspose_conv_4(x)\n",
    "        # print(x.shape)\n",
    "        x = self.up_conv4(torch.cat([x, crop_image(x1, x)], 1))\n",
    "        # print(x.shape)\n",
    "        x = self.out(x)\n",
    "\n",
    "        # print(x.shape)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_path = \"./test.png\"\n",
    "# image = Image.open(image_path)\n",
    "# print(type(image))\n",
    "# image = np.array(image)\n",
    "# print(image.size)\n",
    "# image_tensor = torch.from_numpy(image)\n",
    "# plt.imshow(image_tensor)\n",
    "# image_tensor = image_tensor.float()\n",
    "# image_tensor = image_tensor.permute(2, 0, 1)\n",
    "# image_tensor = image_tensor.unsqueeze(0)\n",
    "# print(image_tensor.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = UNet()\n",
    "# output = model(image_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_image = np.concatenate((output[0][0].detach().numpy(), output[0][1].detach().numpy()), axis=1)\n",
    "# print(output.shape)\n",
    "# plt.imshow(output[0][0].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, image_paths, mask_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # image = Image.open(self.image_paths[idx]).convert(\"L\")\n",
    "        # mask = Image.open(self.mask_paths[idx]).convert(\"L\")\n",
    "        image = Image.open(self.image_paths[idx])\n",
    "        mask = Image.open(self.mask_paths[idx])\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "        \n",
    "        return image, mask\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((1024, 1024)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# test_transform = transforms.Compose([\n",
    "#     transforms.Resize((836, 836)),\n",
    "#     transforms.ToTensor()\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "image_dir = \"./data\"\n",
    "mask_dir = \"./mask\"\n",
    "\n",
    "image_paths = sorted(glob(os.path.join(image_dir, '*.[jp][pn]g')))\n",
    "mask_paths = sorted(glob(os.path.join(mask_dir, '*.[jp][pn]g')))\n",
    "X_train, X_val, y_train, y_val = train_test_split(image_paths, mask_paths, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = SegmentationDataset(X_train, y_train, transform=transform)\n",
    "val_dataset = SegmentationDataset(X_val, y_val, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, optimizer, criterion, num_epochs=20):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        epoch_loss = 0\n",
    "        model.train()  # Ensure the model is in training mode\n",
    "        for images, masks in train_loader:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            # print(outputs.shape)\n",
    "            # print(masks.shape)\n",
    "            masks_resized = F.interpolate(masks, size=outputs.shape[2:], mode='bilinear', align_corners=False)\n",
    "            masks_resized = masks_resized.mean(dim=1, keepdim=True)\n",
    "            loss = criterion(outputs, masks_resized)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss/len(train_loader)}')\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        with torch.no_grad():  # No gradient calculation during validation\n",
    "            val_loss = 0\n",
    "            for images, masks in test_loader:\n",
    "                images = images.to(device)\n",
    "                masks = masks.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                masks_resized = F.interpolate(masks, size=outputs.shape[2:], mode='bilinear', align_corners=False)\n",
    "                masks_resized = masks_resized.mean(dim=1, keepdim=True)\n",
    "                loss = criterion(outputs, masks_resized)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss/len(test_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = UNet()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device(\"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "train(model, train_loader, val_loader, optimizer, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# class SimpleNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(SimpleNN, self).__init__()\n",
    "#         self.fc1 = nn.Linear(3, 3)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.fc1(x)\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = SimpleNN().to(device)\n",
    "\n",
    "# # Test with a small tensor\n",
    "# input_tensor = torch.randn(3, 3).to(device)\n",
    "# output = model(input_tensor)\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Execution Time: 2.5202 seconds\n",
      "GPU Execution Time: 0.3050 seconds\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import time\n",
    "\n",
    "# # Set device\n",
    "# device_cpu = torch.device('cpu')\n",
    "# device_gpu = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# # Define the size of the matrices\n",
    "# matrix_size = 10000  # Adjust this size based on your GPU memory\n",
    "\n",
    "# # Create random matrices on CPU\n",
    "# x_cpu = torch.randn(matrix_size, matrix_size).to(device_cpu)\n",
    "# y_cpu = torch.randn(matrix_size, matrix_size).to(device_cpu)\n",
    "\n",
    "# # Measure execution time on CPU\n",
    "# start_time_cpu = time.time()\n",
    "# z_cpu = torch.matmul(x_cpu, y_cpu)\n",
    "# end_time_cpu = time.time()\n",
    "\n",
    "# # Print CPU results\n",
    "# print(f\"CPU Execution Time: {end_time_cpu - start_time_cpu:.4f} seconds\")\n",
    "\n",
    "# # Create random matrices on GPU\n",
    "# x_gpu = torch.randn(matrix_size, matrix_size).to(device_gpu)\n",
    "# y_gpu = torch.randn(matrix_size, matrix_size).to(device_gpu)\n",
    "\n",
    "# # Measure execution time on GPU\n",
    "# start_time_gpu = time.time()\n",
    "# z_gpu = torch.matmul(x_gpu, y_gpu)\n",
    "# end_time_gpu = time.time()\n",
    "\n",
    "# # Print GPU results\n",
    "# print(f\"GPU Execution Time: {end_time_gpu - start_time_gpu:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average CPU Execution Time: 2.7786 seconds\n",
      "Total CPU Execution Time: 138.9290 seconds\n",
      "Average GPU Execution Time: 0.3309 seconds\n",
      "Total GPU Execution Time: 16.5429 seconds\n"
     ]
    }
   ],
   "source": [
    "# num_runs = 50  # Number of runs for averaging\n",
    "\n",
    "# # CPU timing\n",
    "# cpu_times = []\n",
    "# for _ in range(num_runs):\n",
    "#     start_time_cpu = time.time()\n",
    "#     z_cpu = torch.matmul(x_cpu, y_cpu)\n",
    "#     end_time_cpu = time.time()\n",
    "#     cpu_times.append(end_time_cpu - start_time_cpu)\n",
    "\n",
    "# total_cpu_time = sum(cpu_times)\n",
    "# avg_cpu_time = total_cpu_time / num_runs\n",
    "# print(f\"Average CPU Execution Time: {avg_cpu_time:.4f} seconds\")\n",
    "# print(f\"Total CPU Execution Time: {total_cpu_time:.4f} seconds\")\n",
    "\n",
    "# # GPU timing\n",
    "# gpu_times = []\n",
    "# for _ in range(num_runs):\n",
    "#     start_time_gpu = time.time()\n",
    "#     z_gpu = torch.matmul(x_gpu, y_gpu)\n",
    "#     end_time_gpu = time.time()\n",
    "#     gpu_times.append(end_time_gpu - start_time_gpu)\n",
    "\n",
    "# total_gpu_time = sum(gpu_times)\n",
    "# avg_gpu_time = total_gpu_time / num_runs\n",
    "# print(f\"Average GPU Execution Time: {avg_gpu_time:.4f} seconds\")\n",
    "# print(f\"Total GPU Execution Time: {total_gpu_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

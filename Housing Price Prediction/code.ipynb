{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       208500\n",
       "1       181500\n",
       "2       223500\n",
       "3       140000\n",
       "4       250000\n",
       "         ...  \n",
       "1455    175000\n",
       "1456    210000\n",
       "1457    266500\n",
       "1458    142125\n",
       "1459    147500\n",
       "Name: SalePrice, Length: 1460, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = './data/train.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "data['SalePrice']\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "# print(data.head())\n",
    "# print(data.info())\n",
    "# print(data.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(1460, 233)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# Drop columns with more than 50% missing values\n",
    "threshold = 0.5\n",
    "missing_percentages = data.isnull().mean()\n",
    "columns_to_drop = missing_percentages[missing_percentages > threshold].index\n",
    "data = data.drop(columns=columns_to_drop)\n",
    "\n",
    "# Handle remaining missing values\n",
    "\n",
    "# Fill numerical columns with the median value\n",
    "numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "data[numeric_columns] = data[numeric_columns].fillna(data[numeric_columns].median())\n",
    "\n",
    "# Fill categorical columns with the mode value\n",
    "# categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "# data[categorical_columns] = data[categorical_columns].apply(lambda x: x.fillna(x.mode()[0]))\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "data[categorical_cols] = categorical_imputer.fit_transform(data[categorical_cols])\n",
    "\n",
    "# Encode categorical variables\n",
    "# encoder = LabelEncoder()\n",
    "# for col in categorical_cols:\n",
    "#     data[col] = encoder.fit_transform(data[col])\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "encoded_categorical_cols = pd.DataFrame(encoder.fit_transform(data[categorical_cols]),index=data.index)\n",
    "encoded_categorical_cols.columns = encoder.get_feature_names_out(categorical_cols)\n",
    "data = data.drop(columns=categorical_cols, axis=1).join(encoded_categorical_cols)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "numeric_columns = [x for x in numeric_columns if x != 'SalePrice']\n",
    "data[numeric_columns] = scaler.fit_transform(data[numeric_columns])\n",
    "print(type(data))\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(['Id', 'SalePrice'], axis=1)  # Replace 'target_column' with the actual target column name\n",
    "y = data['SalePrice']\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1168, 233])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).view(-1, 1)\n",
    "print(X_train_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# # Convert data to PyTorch tensors\n",
    "# X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "# y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "# X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "# y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# # Create DataLoader\n",
    "# train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# # Define the neural network model\n",
    "# class HousingPriceModel(nn.Module):\n",
    "#     def __init__(self, input_dim):\n",
    "#         super(HousingPriceModel, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_dim, 64)\n",
    "#         self.fc2 = nn.Linear(64, 32)\n",
    "#         self.fc3 = nn.Linear(32, 1)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = torch.relu(self.fc1(x))\n",
    "#         x = torch.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "#         return x\n",
    "\n",
    "# input_dim = X_train.shape[1]\n",
    "# model = HousingPriceModel(input_dim)\n",
    "\n",
    "# # Define loss function and optimizer\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# # Training loop\n",
    "# num_epochs = 100\n",
    "# for epoch in range(num_epochs):\n",
    "#     for batch_X, batch_y in train_loader:\n",
    "#         # Forward pass\n",
    "#         predictions = model(batch_X)\n",
    "#         loss = criterion(predictions, batch_y)\n",
    "        \n",
    "#         # Backward pass and optimization\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "    \n",
    "#     if (epoch+1) % 10 == 0:\n",
    "#         print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HousingPriceModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(HousingPriceModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class HousingPriceModel(nn.Module):\n",
    "#     def __init__(self, input_dim):\n",
    "#         super(HousingPriceModel, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_dim, 256)\n",
    "#         self.fc2 = nn.Linear(256, 128)\n",
    "#         self.fc3 = nn.Linear(128, 64)\n",
    "#         self.fc4 = nn.Linear(64, 32)\n",
    "#         self.fc5 = nn.Linear(32, 1)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = torch.relu(self.fc1(x))\n",
    "#         x = torch.relu(self.fc2(x))\n",
    "#         x = torch.relu(self.fc3(x))\n",
    "#         x = torch.relu(self.fc4(x))\n",
    "#         x = self.fc5(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class HousingPriceModel(nn.Module):\n",
    "#     def __init__(self, input_dim):\n",
    "#         super(HousingPriceModel, self).__init__()\n",
    "#         self.weights = nn.Parameter(torch.randn(input_dim, 1, dtype=torch.float), requires_grad=True)\n",
    "#         self.bias = nn.Parameter(torch.randn(1, dtype=torch.float), requires_grad=True)\n",
    "#     def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "#         return torch.matmul(x, self.weights) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn.init as init\n",
    "\n",
    "# class HousingPriceModel(nn.Module):\n",
    "#     def __init__(self, input_dim):\n",
    "#         super(HousingPriceModel, self).__init__()\n",
    "#         self.weights = nn.Parameter(torch.empty(input_dim, 1, dtype=torch.float))\n",
    "#         self.bias = nn.Parameter(torch.empty(1, dtype=torch.float))\n",
    "\n",
    "#         # Initialize weights using Xavier uniform initialization\n",
    "#         init.xavier_uniform_(self.weights)\n",
    "#         # Initialize bias with zeros or a small constant\n",
    "#         init.zeros_(self.bias)\n",
    "\n",
    "#     def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "#         return torch.matmul(x, self.weights) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train_tensor.shape[1]\n",
    "model = HousingPriceModel(input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[145000.],\n",
      "        [178000.],\n",
      "        [ 85000.],\n",
      "        [175000.],\n",
      "        [127000.]])\n",
      "tensor([[-0.1345],\n",
      "        [-0.0704],\n",
      "        [-0.1380],\n",
      "        [-0.0675],\n",
      "        [-0.0325]])\n"
     ]
    }
   ],
   "source": [
    "#for testing the random initialization\n",
    "with torch.inference_mode():\n",
    "    y_preds = model(X_train_tensor)\n",
    "print(y_train_tensor[:5])\n",
    "print(y_preds[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/5000], Training Loss: 181441.3438, Validation Loss: 178839.5938\n",
      "Epoch [20/5000], Training Loss: 181440.8750, Validation Loss: 178839.0625\n",
      "Epoch [30/5000], Training Loss: 181439.8750, Validation Loss: 178838.0156\n",
      "Epoch [40/5000], Training Loss: 181438.0000, Validation Loss: 178836.0625\n",
      "Epoch [50/5000], Training Loss: 181434.7344, Validation Loss: 178832.6875\n",
      "Epoch [60/5000], Training Loss: 181429.4688, Validation Loss: 178827.3281\n",
      "Epoch [70/5000], Training Loss: 181421.4062, Validation Loss: 178819.1719\n",
      "Epoch [80/5000], Training Loss: 181409.6094, Validation Loss: 178807.2812\n",
      "Epoch [90/5000], Training Loss: 181392.9688, Validation Loss: 178790.6719\n",
      "Epoch [100/5000], Training Loss: 181370.3594, Validation Loss: 178768.1875\n",
      "Epoch [110/5000], Training Loss: 181340.5469, Validation Loss: 178738.6719\n",
      "Epoch [120/5000], Training Loss: 181302.3281, Validation Loss: 178701.0156\n",
      "Epoch [130/5000], Training Loss: 181254.4375, Validation Loss: 178653.9531\n",
      "Epoch [140/5000], Training Loss: 181195.7188, Validation Loss: 178596.4688\n",
      "Epoch [150/5000], Training Loss: 181125.0000, Validation Loss: 178527.4219\n",
      "Epoch [160/5000], Training Loss: 181041.0625, Validation Loss: 178445.7031\n",
      "Epoch [170/5000], Training Loss: 180942.6875, Validation Loss: 178350.1094\n",
      "Epoch [180/5000], Training Loss: 180828.5781, Validation Loss: 178239.3906\n",
      "Epoch [190/5000], Training Loss: 180697.5469, Validation Loss: 178112.5000\n",
      "Epoch [200/5000], Training Loss: 180548.4844, Validation Loss: 177968.3281\n",
      "Epoch [210/5000], Training Loss: 180380.2344, Validation Loss: 177805.8594\n",
      "Epoch [220/5000], Training Loss: 180191.6719, Validation Loss: 177624.0156\n",
      "Epoch [230/5000], Training Loss: 179981.7031, Validation Loss: 177421.7656\n",
      "Epoch [240/5000], Training Loss: 179749.2812, Validation Loss: 177198.1094\n",
      "Epoch [250/5000], Training Loss: 179493.2812, Validation Loss: 176952.0000\n",
      "Epoch [260/5000], Training Loss: 179212.6562, Validation Loss: 176682.5000\n",
      "Epoch [270/5000], Training Loss: 178906.4219, Validation Loss: 176388.5469\n",
      "Epoch [280/5000], Training Loss: 178573.4531, Validation Loss: 176069.2344\n",
      "Epoch [290/5000], Training Loss: 178212.8125, Validation Loss: 175723.5312\n",
      "Epoch [300/5000], Training Loss: 177823.4062, Validation Loss: 175350.5469\n",
      "Epoch [310/5000], Training Loss: 177404.2969, Validation Loss: 174949.3594\n",
      "Epoch [320/5000], Training Loss: 176954.5000, Validation Loss: 174519.0000\n",
      "Epoch [330/5000], Training Loss: 176472.9844, Validation Loss: 174058.5625\n",
      "Epoch [340/5000], Training Loss: 175958.8906, Validation Loss: 173567.1250\n",
      "Epoch [350/5000], Training Loss: 175411.2031, Validation Loss: 173043.8438\n",
      "Epoch [360/5000], Training Loss: 174828.9844, Validation Loss: 172487.7969\n",
      "Epoch [370/5000], Training Loss: 174211.3438, Validation Loss: 171898.1094\n",
      "Epoch [380/5000], Training Loss: 173557.3281, Validation Loss: 171273.9375\n",
      "Epoch [390/5000], Training Loss: 172866.0625, Validation Loss: 170614.4375\n",
      "Epoch [400/5000], Training Loss: 172136.6719, Validation Loss: 169918.7656\n",
      "Epoch [410/5000], Training Loss: 171368.2500, Validation Loss: 169186.0781\n",
      "Epoch [420/5000], Training Loss: 170559.9062, Validation Loss: 168415.5625\n",
      "Epoch [430/5000], Training Loss: 169710.8281, Validation Loss: 167606.4062\n",
      "Epoch [440/5000], Training Loss: 168820.1562, Validation Loss: 166757.8125\n",
      "Epoch [450/5000], Training Loss: 167887.0156, Validation Loss: 165869.0000\n",
      "Epoch [460/5000], Training Loss: 166910.6094, Validation Loss: 164939.1562\n",
      "Epoch [470/5000], Training Loss: 165890.1250, Validation Loss: 163967.5156\n",
      "Epoch [480/5000], Training Loss: 164824.7344, Validation Loss: 162953.3594\n",
      "Epoch [490/5000], Training Loss: 163713.6406, Validation Loss: 161895.8594\n",
      "Epoch [500/5000], Training Loss: 162556.0625, Validation Loss: 160794.3281\n",
      "Epoch [510/5000], Training Loss: 161351.2031, Validation Loss: 159648.0625\n",
      "Epoch [520/5000], Training Loss: 160098.3125, Validation Loss: 158456.2188\n",
      "Epoch [530/5000], Training Loss: 158796.6250, Validation Loss: 157218.1719\n",
      "Epoch [540/5000], Training Loss: 157445.3438, Validation Loss: 155933.1719\n",
      "Epoch [550/5000], Training Loss: 156043.7500, Validation Loss: 154600.5156\n",
      "Epoch [560/5000], Training Loss: 154591.1406, Validation Loss: 153219.5469\n",
      "Epoch [570/5000], Training Loss: 153086.7188, Validation Loss: 151789.5312\n",
      "Epoch [580/5000], Training Loss: 151529.8281, Validation Loss: 150309.8281\n",
      "Epoch [590/5000], Training Loss: 149919.7344, Validation Loss: 148779.7344\n",
      "Epoch [600/5000], Training Loss: 148255.7188, Validation Loss: 147198.6094\n",
      "Epoch [610/5000], Training Loss: 146537.0938, Validation Loss: 145565.7812\n",
      "Epoch [620/5000], Training Loss: 144763.1719, Validation Loss: 143880.6094\n",
      "Epoch [630/5000], Training Loss: 142933.2812, Validation Loss: 142142.4531\n",
      "Epoch [640/5000], Training Loss: 141046.7344, Validation Loss: 140350.6719\n",
      "Epoch [650/5000], Training Loss: 139102.8906, Validation Loss: 138504.6719\n",
      "Epoch [660/5000], Training Loss: 137101.0625, Validation Loss: 136603.7812\n",
      "Epoch [670/5000], Training Loss: 135040.6094, Validation Loss: 134647.4219\n",
      "Epoch [680/5000], Training Loss: 132920.9219, Validation Loss: 132634.9844\n",
      "Epoch [690/5000], Training Loss: 130747.0391, Validation Loss: 130565.0938\n",
      "Epoch [700/5000], Training Loss: 128525.7969, Validation Loss: 128436.3984\n",
      "Epoch [710/5000], Training Loss: 126246.8047, Validation Loss: 126250.0859\n",
      "Epoch [720/5000], Training Loss: 123907.3828, Validation Loss: 124005.1250\n",
      "Epoch [730/5000], Training Loss: 121506.3125, Validation Loss: 121700.7969\n",
      "Epoch [740/5000], Training Loss: 119042.7422, Validation Loss: 119336.4688\n",
      "Epoch [750/5000], Training Loss: 116516.0000, Validation Loss: 116911.5234\n",
      "Epoch [760/5000], Training Loss: 113927.1250, Validation Loss: 114425.8438\n",
      "Epoch [770/5000], Training Loss: 111277.9688, Validation Loss: 111880.5391\n",
      "Epoch [780/5000], Training Loss: 108574.6719, Validation Loss: 109276.8516\n",
      "Epoch [790/5000], Training Loss: 105815.7812, Validation Loss: 106615.7344\n",
      "Epoch [800/5000], Training Loss: 103004.2344, Validation Loss: 103919.2422\n",
      "Epoch [810/5000], Training Loss: 100129.6328, Validation Loss: 101161.8516\n",
      "Epoch [820/5000], Training Loss: 97197.0703, Validation Loss: 98344.0859\n",
      "Epoch [830/5000], Training Loss: 94201.9062, Validation Loss: 95479.9453\n",
      "Epoch [840/5000], Training Loss: 91156.3906, Validation Loss: 92553.9062\n",
      "Epoch [850/5000], Training Loss: 88060.3594, Validation Loss: 89566.7734\n",
      "Epoch [860/5000], Training Loss: 84918.0391, Validation Loss: 86535.7656\n",
      "Epoch [870/5000], Training Loss: 81733.2500, Validation Loss: 83466.3047\n",
      "Epoch [880/5000], Training Loss: 78508.3516, Validation Loss: 80342.2656\n",
      "Epoch [890/5000], Training Loss: 75248.8203, Validation Loss: 77183.1953\n",
      "Epoch [900/5000], Training Loss: 71960.5156, Validation Loss: 73986.1797\n",
      "Epoch [910/5000], Training Loss: 68628.4062, Validation Loss: 70756.4844\n",
      "Epoch [920/5000], Training Loss: 65271.3281, Validation Loss: 67474.0000\n",
      "Epoch [930/5000], Training Loss: 61928.7656, Validation Loss: 64195.0703\n",
      "Epoch [940/5000], Training Loss: 58619.8086, Validation Loss: 60961.1562\n",
      "Epoch [950/5000], Training Loss: 55349.1211, Validation Loss: 57778.7656\n",
      "Epoch [960/5000], Training Loss: 52175.5938, Validation Loss: 54714.3750\n",
      "Epoch [970/5000], Training Loss: 49101.3867, Validation Loss: 51712.9336\n",
      "Epoch [980/5000], Training Loss: 46146.2617, Validation Loss: 48812.7930\n",
      "Epoch [990/5000], Training Loss: 43327.5195, Validation Loss: 46002.5156\n",
      "Epoch [1000/5000], Training Loss: 40698.9297, Validation Loss: 43337.0625\n",
      "Epoch [1010/5000], Training Loss: 38230.6211, Validation Loss: 40820.6836\n",
      "Epoch [1020/5000], Training Loss: 35933.4219, Validation Loss: 38436.3867\n",
      "Epoch [1030/5000], Training Loss: 33893.4297, Validation Loss: 36309.1602\n",
      "Epoch [1040/5000], Training Loss: 32139.8496, Validation Loss: 34486.3359\n",
      "Epoch [1050/5000], Training Loss: 30659.4180, Validation Loss: 32904.6016\n",
      "Epoch [1060/5000], Training Loss: 29462.5723, Validation Loss: 31614.9277\n",
      "Epoch [1070/5000], Training Loss: 28521.6504, Validation Loss: 30556.0137\n",
      "Epoch [1080/5000], Training Loss: 27776.4238, Validation Loss: 29695.7227\n",
      "Epoch [1090/5000], Training Loss: 27199.7988, Validation Loss: 29013.8633\n",
      "Epoch [1100/5000], Training Loss: 26775.2676, Validation Loss: 28458.8770\n",
      "Epoch [1110/5000], Training Loss: 26443.0293, Validation Loss: 28020.0996\n",
      "Epoch [1120/5000], Training Loss: 26167.7578, Validation Loss: 27650.8828\n",
      "Epoch [1130/5000], Training Loss: 25935.5703, Validation Loss: 27331.9043\n",
      "Epoch [1140/5000], Training Loss: 25731.7461, Validation Loss: 27059.5918\n",
      "Epoch [1150/5000], Training Loss: 25550.6855, Validation Loss: 26814.7578\n",
      "Epoch [1160/5000], Training Loss: 25382.8789, Validation Loss: 26599.3086\n",
      "Epoch [1170/5000], Training Loss: 25229.3965, Validation Loss: 26415.5215\n",
      "Epoch [1180/5000], Training Loss: 25089.1504, Validation Loss: 26249.6738\n",
      "Epoch [1190/5000], Training Loss: 24959.8340, Validation Loss: 26099.3223\n",
      "Epoch [1200/5000], Training Loss: 24837.2363, Validation Loss: 25959.1934\n",
      "Epoch [1210/5000], Training Loss: 24722.2480, Validation Loss: 25834.9629\n",
      "Epoch [1220/5000], Training Loss: 24610.9590, Validation Loss: 25716.3398\n",
      "Epoch [1230/5000], Training Loss: 24502.4414, Validation Loss: 25606.5312\n",
      "Epoch [1240/5000], Training Loss: 24396.7051, Validation Loss: 25500.2363\n",
      "Epoch [1250/5000], Training Loss: 24296.5840, Validation Loss: 25401.6602\n",
      "Epoch [1260/5000], Training Loss: 24201.3398, Validation Loss: 25314.0352\n",
      "Epoch [1270/5000], Training Loss: 24112.8516, Validation Loss: 25234.9863\n",
      "Epoch [1280/5000], Training Loss: 24029.5820, Validation Loss: 25159.9531\n",
      "Epoch [1290/5000], Training Loss: 23948.5996, Validation Loss: 25087.9355\n",
      "Epoch [1300/5000], Training Loss: 23869.5371, Validation Loss: 25020.1309\n",
      "Epoch [1310/5000], Training Loss: 23792.6172, Validation Loss: 24956.3047\n",
      "Epoch [1320/5000], Training Loss: 23717.3652, Validation Loss: 24895.4746\n",
      "Epoch [1330/5000], Training Loss: 23643.4199, Validation Loss: 24836.0312\n",
      "Epoch [1340/5000], Training Loss: 23571.8906, Validation Loss: 24776.0898\n",
      "Epoch [1350/5000], Training Loss: 23502.3379, Validation Loss: 24716.4648\n",
      "Epoch [1360/5000], Training Loss: 23433.7852, Validation Loss: 24656.9648\n",
      "Epoch [1370/5000], Training Loss: 23366.2285, Validation Loss: 24600.4219\n",
      "Epoch [1380/5000], Training Loss: 23300.8691, Validation Loss: 24543.7500\n",
      "Epoch [1390/5000], Training Loss: 23236.8438, Validation Loss: 24487.9805\n",
      "Epoch [1400/5000], Training Loss: 23174.5742, Validation Loss: 24429.2852\n",
      "Epoch [1410/5000], Training Loss: 23113.0215, Validation Loss: 24369.7715\n",
      "Epoch [1420/5000], Training Loss: 23052.6504, Validation Loss: 24312.4102\n",
      "Epoch [1430/5000], Training Loss: 22993.4785, Validation Loss: 24257.0586\n",
      "Epoch [1440/5000], Training Loss: 22934.4375, Validation Loss: 24202.4609\n",
      "Epoch [1450/5000], Training Loss: 22875.9961, Validation Loss: 24149.6074\n",
      "Epoch [1460/5000], Training Loss: 22818.0918, Validation Loss: 24098.7754\n",
      "Epoch [1470/5000], Training Loss: 22761.2070, Validation Loss: 24050.9102\n",
      "Epoch [1480/5000], Training Loss: 22705.1738, Validation Loss: 24005.5840\n",
      "Epoch [1490/5000], Training Loss: 22649.4746, Validation Loss: 23962.6699\n",
      "Epoch [1500/5000], Training Loss: 22594.1328, Validation Loss: 23917.8789\n",
      "Epoch [1510/5000], Training Loss: 22539.4395, Validation Loss: 23873.9004\n",
      "Epoch [1520/5000], Training Loss: 22485.1191, Validation Loss: 23835.1582\n",
      "Epoch [1530/5000], Training Loss: 22432.2988, Validation Loss: 23796.8184\n",
      "Epoch [1540/5000], Training Loss: 22380.5918, Validation Loss: 23759.9102\n",
      "Epoch [1550/5000], Training Loss: 22329.7441, Validation Loss: 23723.5918\n",
      "Epoch [1560/5000], Training Loss: 22279.5488, Validation Loss: 23686.7832\n",
      "Epoch [1570/5000], Training Loss: 22229.9648, Validation Loss: 23650.0293\n",
      "Epoch [1580/5000], Training Loss: 22181.5215, Validation Loss: 23611.9688\n",
      "Epoch [1590/5000], Training Loss: 22133.9219, Validation Loss: 23572.4863\n",
      "Epoch [1600/5000], Training Loss: 22086.8496, Validation Loss: 23532.2988\n",
      "Epoch [1610/5000], Training Loss: 22040.1992, Validation Loss: 23493.1113\n",
      "Epoch [1620/5000], Training Loss: 21993.9922, Validation Loss: 23452.8965\n",
      "Epoch [1630/5000], Training Loss: 21947.9727, Validation Loss: 23411.4785\n",
      "Epoch [1640/5000], Training Loss: 21901.9531, Validation Loss: 23370.4062\n",
      "Epoch [1650/5000], Training Loss: 21856.1270, Validation Loss: 23329.9727\n",
      "Epoch [1660/5000], Training Loss: 21810.5449, Validation Loss: 23290.2988\n",
      "Epoch [1670/5000], Training Loss: 21765.6367, Validation Loss: 23251.9277\n",
      "Epoch [1680/5000], Training Loss: 21720.8809, Validation Loss: 23214.9375\n",
      "Epoch [1690/5000], Training Loss: 21676.7988, Validation Loss: 23177.4141\n",
      "Epoch [1700/5000], Training Loss: 21633.0645, Validation Loss: 23140.5645\n",
      "Epoch [1710/5000], Training Loss: 21589.2676, Validation Loss: 23104.7871\n",
      "Epoch [1720/5000], Training Loss: 21545.9570, Validation Loss: 23069.5410\n",
      "Epoch [1730/5000], Training Loss: 21502.5996, Validation Loss: 23033.9160\n",
      "Epoch [1740/5000], Training Loss: 21459.1270, Validation Loss: 22998.3066\n",
      "Epoch [1750/5000], Training Loss: 21415.5156, Validation Loss: 22963.3926\n",
      "Epoch [1760/5000], Training Loss: 21371.7520, Validation Loss: 22928.8184\n",
      "Epoch [1770/5000], Training Loss: 21327.9336, Validation Loss: 22895.2910\n",
      "Epoch [1780/5000], Training Loss: 21283.9980, Validation Loss: 22862.0664\n",
      "Epoch [1790/5000], Training Loss: 21240.3574, Validation Loss: 22830.5312\n",
      "Epoch [1800/5000], Training Loss: 21197.0352, Validation Loss: 22799.4922\n",
      "Epoch [1810/5000], Training Loss: 21154.2617, Validation Loss: 22768.4688\n",
      "Epoch [1820/5000], Training Loss: 21111.9258, Validation Loss: 22740.3203\n",
      "Epoch [1830/5000], Training Loss: 21069.5078, Validation Loss: 22711.8027\n",
      "Epoch [1840/5000], Training Loss: 21027.3770, Validation Loss: 22684.1816\n",
      "Epoch [1850/5000], Training Loss: 20985.3320, Validation Loss: 22658.3379\n",
      "Epoch [1860/5000], Training Loss: 20943.2949, Validation Loss: 22632.8828\n",
      "Epoch [1870/5000], Training Loss: 20901.5391, Validation Loss: 22608.8008\n",
      "Epoch [1880/5000], Training Loss: 20860.2734, Validation Loss: 22586.0586\n",
      "Epoch [1890/5000], Training Loss: 20819.2930, Validation Loss: 22564.0781\n",
      "Epoch [1900/5000], Training Loss: 20778.5117, Validation Loss: 22540.7793\n",
      "Epoch [1910/5000], Training Loss: 20737.7148, Validation Loss: 22517.2715\n",
      "Epoch [1920/5000], Training Loss: 20697.6641, Validation Loss: 22491.9062\n",
      "Epoch [1930/5000], Training Loss: 20658.2285, Validation Loss: 22465.9336\n",
      "Epoch [1940/5000], Training Loss: 20618.9629, Validation Loss: 22440.1445\n",
      "Epoch [1950/5000], Training Loss: 20580.4863, Validation Loss: 22415.5996\n",
      "Epoch [1960/5000], Training Loss: 20542.1797, Validation Loss: 22391.5332\n",
      "Epoch [1970/5000], Training Loss: 20503.7988, Validation Loss: 22366.9746\n",
      "Epoch [1980/5000], Training Loss: 20465.3379, Validation Loss: 22342.4727\n",
      "Epoch [1990/5000], Training Loss: 20427.3008, Validation Loss: 22318.9453\n",
      "Epoch [2000/5000], Training Loss: 20389.5234, Validation Loss: 22295.3574\n",
      "Epoch [2010/5000], Training Loss: 20351.9102, Validation Loss: 22271.1016\n",
      "Epoch [2020/5000], Training Loss: 20314.5098, Validation Loss: 22246.7812\n",
      "Epoch [2030/5000], Training Loss: 20277.1328, Validation Loss: 22223.6426\n",
      "Epoch [2040/5000], Training Loss: 20239.7578, Validation Loss: 22200.7148\n",
      "Epoch [2050/5000], Training Loss: 20202.3066, Validation Loss: 22178.0723\n",
      "Epoch [2060/5000], Training Loss: 20164.7070, Validation Loss: 22155.2383\n",
      "Epoch [2070/5000], Training Loss: 20127.1816, Validation Loss: 22132.7090\n",
      "Epoch [2080/5000], Training Loss: 20089.6035, Validation Loss: 22111.8242\n",
      "Epoch [2090/5000], Training Loss: 20051.9238, Validation Loss: 22090.3438\n",
      "Epoch [2100/5000], Training Loss: 20014.1562, Validation Loss: 22069.4102\n",
      "Epoch [2110/5000], Training Loss: 19976.6445, Validation Loss: 22048.7715\n",
      "Epoch [2120/5000], Training Loss: 19939.5156, Validation Loss: 22028.8359\n",
      "Epoch [2130/5000], Training Loss: 19902.6953, Validation Loss: 22009.5898\n",
      "Epoch [2140/5000], Training Loss: 19865.9590, Validation Loss: 21990.9219\n",
      "Epoch [2150/5000], Training Loss: 19829.4551, Validation Loss: 21971.0762\n",
      "Epoch [2160/5000], Training Loss: 19793.2793, Validation Loss: 21951.3730\n",
      "Epoch [2170/5000], Training Loss: 19757.3633, Validation Loss: 21931.4551\n",
      "Epoch [2180/5000], Training Loss: 19722.0000, Validation Loss: 21912.4648\n",
      "Epoch [2190/5000], Training Loss: 19686.8945, Validation Loss: 21892.3535\n",
      "Epoch [2200/5000], Training Loss: 19651.8125, Validation Loss: 21871.5684\n",
      "Epoch [2210/5000], Training Loss: 19616.9648, Validation Loss: 21848.7344\n",
      "Epoch [2220/5000], Training Loss: 19582.0820, Validation Loss: 21827.2148\n",
      "Epoch [2230/5000], Training Loss: 19547.4492, Validation Loss: 21805.4766\n",
      "Epoch [2240/5000], Training Loss: 19512.9434, Validation Loss: 21782.1387\n",
      "Epoch [2250/5000], Training Loss: 19478.8438, Validation Loss: 21758.3184\n",
      "Epoch [2260/5000], Training Loss: 19444.8516, Validation Loss: 21735.2676\n",
      "Epoch [2270/5000], Training Loss: 19410.7754, Validation Loss: 21712.1289\n",
      "Epoch [2280/5000], Training Loss: 19376.6680, Validation Loss: 21689.6113\n",
      "Epoch [2290/5000], Training Loss: 19342.5039, Validation Loss: 21666.7871\n",
      "Epoch [2300/5000], Training Loss: 19308.1855, Validation Loss: 21643.8633\n",
      "Epoch [2310/5000], Training Loss: 19273.7598, Validation Loss: 21620.8867\n",
      "Epoch [2320/5000], Training Loss: 19239.4102, Validation Loss: 21598.1289\n",
      "Epoch [2330/5000], Training Loss: 19205.3770, Validation Loss: 21575.0742\n",
      "Epoch [2340/5000], Training Loss: 19171.2598, Validation Loss: 21553.3418\n",
      "Epoch [2350/5000], Training Loss: 19137.4062, Validation Loss: 21530.4199\n",
      "Epoch [2360/5000], Training Loss: 19103.8145, Validation Loss: 21508.0234\n",
      "Epoch [2370/5000], Training Loss: 19070.5000, Validation Loss: 21486.0488\n",
      "Epoch [2380/5000], Training Loss: 19038.1797, Validation Loss: 21466.1973\n",
      "Epoch [2390/5000], Training Loss: 19006.0762, Validation Loss: 21447.2090\n",
      "Epoch [2400/5000], Training Loss: 18974.0527, Validation Loss: 21428.5371\n",
      "Epoch [2410/5000], Training Loss: 18942.4766, Validation Loss: 21410.4414\n",
      "Epoch [2420/5000], Training Loss: 18911.4453, Validation Loss: 21392.7871\n",
      "Epoch [2430/5000], Training Loss: 18880.7578, Validation Loss: 21375.3828\n",
      "Epoch [2440/5000], Training Loss: 18849.9668, Validation Loss: 21357.9551\n",
      "Epoch [2450/5000], Training Loss: 18819.0918, Validation Loss: 21341.1777\n",
      "Epoch [2460/5000], Training Loss: 18788.6738, Validation Loss: 21325.5742\n",
      "Epoch [2470/5000], Training Loss: 18758.4512, Validation Loss: 21309.2207\n",
      "Epoch [2480/5000], Training Loss: 18728.6914, Validation Loss: 21293.6230\n",
      "Epoch [2490/5000], Training Loss: 18699.4277, Validation Loss: 21277.7930\n",
      "Epoch [2500/5000], Training Loss: 18670.6133, Validation Loss: 21262.1699\n",
      "Epoch [2510/5000], Training Loss: 18641.8320, Validation Loss: 21246.6328\n",
      "Epoch [2520/5000], Training Loss: 18612.9922, Validation Loss: 21230.6055\n",
      "Epoch [2530/5000], Training Loss: 18584.0781, Validation Loss: 21213.7715\n",
      "Epoch [2540/5000], Training Loss: 18555.2188, Validation Loss: 21196.3574\n",
      "Epoch [2550/5000], Training Loss: 18526.8398, Validation Loss: 21179.5449\n",
      "Epoch [2560/5000], Training Loss: 18498.5801, Validation Loss: 21162.7246\n",
      "Epoch [2570/5000], Training Loss: 18470.6055, Validation Loss: 21145.8496\n",
      "Epoch [2580/5000], Training Loss: 18442.8496, Validation Loss: 21129.8340\n",
      "Epoch [2590/5000], Training Loss: 18415.3125, Validation Loss: 21113.3066\n",
      "Epoch [2600/5000], Training Loss: 18387.8359, Validation Loss: 21096.5410\n",
      "Epoch [2610/5000], Training Loss: 18360.2969, Validation Loss: 21079.2051\n",
      "Epoch [2620/5000], Training Loss: 18332.8594, Validation Loss: 21061.6035\n",
      "Epoch [2630/5000], Training Loss: 18305.3828, Validation Loss: 21042.9375\n",
      "Epoch [2640/5000], Training Loss: 18277.9824, Validation Loss: 21026.0645\n",
      "Epoch [2650/5000], Training Loss: 18250.5957, Validation Loss: 21008.6992\n",
      "Epoch [2660/5000], Training Loss: 18223.2910, Validation Loss: 20991.1133\n",
      "Epoch [2670/5000], Training Loss: 18196.0273, Validation Loss: 20973.0879\n",
      "Epoch [2680/5000], Training Loss: 18168.7715, Validation Loss: 20954.5449\n",
      "Epoch [2690/5000], Training Loss: 18141.5059, Validation Loss: 20936.2070\n",
      "Epoch [2700/5000], Training Loss: 18114.5176, Validation Loss: 20917.5527\n",
      "Epoch [2710/5000], Training Loss: 18087.5586, Validation Loss: 20898.7031\n",
      "Epoch [2720/5000], Training Loss: 18060.8770, Validation Loss: 20879.9805\n",
      "Epoch [2730/5000], Training Loss: 18034.2207, Validation Loss: 20860.9551\n",
      "Epoch [2740/5000], Training Loss: 18007.6230, Validation Loss: 20842.4551\n",
      "Epoch [2750/5000], Training Loss: 17980.9844, Validation Loss: 20823.7852\n",
      "Epoch [2760/5000], Training Loss: 17954.5488, Validation Loss: 20804.8906\n",
      "Epoch [2770/5000], Training Loss: 17928.8320, Validation Loss: 20787.2715\n",
      "Epoch [2780/5000], Training Loss: 17903.2012, Validation Loss: 20769.5840\n",
      "Epoch [2790/5000], Training Loss: 17877.5273, Validation Loss: 20752.3281\n",
      "Epoch [2800/5000], Training Loss: 17852.3125, Validation Loss: 20735.1680\n",
      "Epoch [2810/5000], Training Loss: 17827.3203, Validation Loss: 20717.9551\n",
      "Epoch [2820/5000], Training Loss: 17802.4746, Validation Loss: 20701.0488\n",
      "Epoch [2830/5000], Training Loss: 17777.9062, Validation Loss: 20684.5547\n",
      "Epoch [2840/5000], Training Loss: 17753.5762, Validation Loss: 20667.8770\n",
      "Epoch [2850/5000], Training Loss: 17729.1758, Validation Loss: 20652.4375\n",
      "Epoch [2860/5000], Training Loss: 17704.9902, Validation Loss: 20636.7539\n",
      "Epoch [2870/5000], Training Loss: 17681.1543, Validation Loss: 20621.6797\n",
      "Epoch [2880/5000], Training Loss: 17657.5215, Validation Loss: 20606.6660\n",
      "Epoch [2890/5000], Training Loss: 17633.9824, Validation Loss: 20591.0586\n",
      "Epoch [2900/5000], Training Loss: 17610.8984, Validation Loss: 20576.4258\n",
      "Epoch [2910/5000], Training Loss: 17587.8555, Validation Loss: 20562.1875\n",
      "Epoch [2920/5000], Training Loss: 17564.9160, Validation Loss: 20548.3242\n",
      "Epoch [2930/5000], Training Loss: 17542.1387, Validation Loss: 20535.1152\n",
      "Epoch [2940/5000], Training Loss: 17519.6953, Validation Loss: 20521.4043\n",
      "Epoch [2950/5000], Training Loss: 17497.7383, Validation Loss: 20506.5898\n",
      "Epoch [2960/5000], Training Loss: 17476.2637, Validation Loss: 20493.2324\n",
      "Epoch [2970/5000], Training Loss: 17454.9727, Validation Loss: 20480.4414\n",
      "Epoch [2980/5000], Training Loss: 17433.6621, Validation Loss: 20466.4102\n",
      "Epoch [2990/5000], Training Loss: 17412.6309, Validation Loss: 20452.8262\n",
      "Epoch [3000/5000], Training Loss: 17391.6289, Validation Loss: 20439.6172\n",
      "Epoch [3010/5000], Training Loss: 17370.7578, Validation Loss: 20426.7129\n",
      "Epoch [3020/5000], Training Loss: 17350.3320, Validation Loss: 20413.8652\n",
      "Epoch [3030/5000], Training Loss: 17330.1016, Validation Loss: 20402.4102\n",
      "Epoch [3040/5000], Training Loss: 17310.1074, Validation Loss: 20391.3555\n",
      "Epoch [3050/5000], Training Loss: 17290.0762, Validation Loss: 20380.4785\n",
      "Epoch [3060/5000], Training Loss: 17270.0820, Validation Loss: 20369.6445\n",
      "Epoch [3070/5000], Training Loss: 17250.3652, Validation Loss: 20358.2188\n",
      "Epoch [3080/5000], Training Loss: 17231.3809, Validation Loss: 20347.1875\n",
      "Epoch [3090/5000], Training Loss: 17212.6113, Validation Loss: 20334.9004\n",
      "Epoch [3100/5000], Training Loss: 17193.9121, Validation Loss: 20322.2539\n",
      "Epoch [3110/5000], Training Loss: 17175.3086, Validation Loss: 20308.8965\n",
      "Epoch [3120/5000], Training Loss: 17156.7852, Validation Loss: 20296.4746\n",
      "Epoch [3130/5000], Training Loss: 17138.1738, Validation Loss: 20283.9180\n",
      "Epoch [3140/5000], Training Loss: 17119.6426, Validation Loss: 20272.0352\n",
      "Epoch [3150/5000], Training Loss: 17101.0957, Validation Loss: 20260.6777\n",
      "Epoch [3160/5000], Training Loss: 17082.7305, Validation Loss: 20249.8320\n",
      "Epoch [3170/5000], Training Loss: 17064.4648, Validation Loss: 20238.3398\n",
      "Epoch [3180/5000], Training Loss: 17046.1875, Validation Loss: 20227.0176\n",
      "Epoch [3190/5000], Training Loss: 17028.2500, Validation Loss: 20215.6797\n",
      "Epoch [3200/5000], Training Loss: 17010.4648, Validation Loss: 20205.0625\n",
      "Epoch [3210/5000], Training Loss: 16992.7441, Validation Loss: 20193.7578\n",
      "Epoch [3220/5000], Training Loss: 16975.0547, Validation Loss: 20181.3105\n",
      "Epoch [3230/5000], Training Loss: 16957.2812, Validation Loss: 20168.9824\n",
      "Epoch [3240/5000], Training Loss: 16939.4238, Validation Loss: 20156.2461\n",
      "Epoch [3250/5000], Training Loss: 16921.6309, Validation Loss: 20143.5645\n",
      "Epoch [3260/5000], Training Loss: 16903.8789, Validation Loss: 20130.6543\n",
      "Epoch [3270/5000], Training Loss: 16886.3867, Validation Loss: 20118.1035\n",
      "Epoch [3280/5000], Training Loss: 16868.8340, Validation Loss: 20105.2578\n",
      "Epoch [3290/5000], Training Loss: 16851.5312, Validation Loss: 20092.0898\n",
      "Epoch [3300/5000], Training Loss: 16834.1777, Validation Loss: 20078.9023\n",
      "Epoch [3310/5000], Training Loss: 16816.8398, Validation Loss: 20065.5938\n",
      "Epoch [3320/5000], Training Loss: 16799.3984, Validation Loss: 20051.6895\n",
      "Epoch [3330/5000], Training Loss: 16782.3223, Validation Loss: 20037.8809\n",
      "Epoch [3340/5000], Training Loss: 16765.5293, Validation Loss: 20024.2148\n",
      "Epoch [3350/5000], Training Loss: 16749.0332, Validation Loss: 20012.1484\n",
      "Epoch [3360/5000], Training Loss: 16732.8320, Validation Loss: 19998.6953\n",
      "Epoch [3370/5000], Training Loss: 16716.6816, Validation Loss: 19985.3965\n",
      "Epoch [3380/5000], Training Loss: 16700.7539, Validation Loss: 19972.9668\n",
      "Epoch [3390/5000], Training Loss: 16684.8672, Validation Loss: 19960.7891\n",
      "Epoch [3400/5000], Training Loss: 16669.1250, Validation Loss: 19948.5430\n",
      "Epoch [3410/5000], Training Loss: 16653.5488, Validation Loss: 19937.2168\n",
      "Epoch [3420/5000], Training Loss: 16638.2363, Validation Loss: 19927.3535\n",
      "Epoch [3430/5000], Training Loss: 16623.0547, Validation Loss: 19917.9434\n",
      "Epoch [3440/5000], Training Loss: 16607.9336, Validation Loss: 19908.9238\n",
      "Epoch [3450/5000], Training Loss: 16592.8555, Validation Loss: 19901.2148\n",
      "Epoch [3460/5000], Training Loss: 16577.7246, Validation Loss: 19894.0547\n",
      "Epoch [3470/5000], Training Loss: 16562.5352, Validation Loss: 19887.2988\n",
      "Epoch [3480/5000], Training Loss: 16547.3125, Validation Loss: 19879.8047\n",
      "Epoch [3490/5000], Training Loss: 16532.2793, Validation Loss: 19872.6445\n",
      "Epoch [3500/5000], Training Loss: 16517.2910, Validation Loss: 19865.3105\n",
      "Epoch [3510/5000], Training Loss: 16502.3477, Validation Loss: 19858.3203\n",
      "Epoch [3520/5000], Training Loss: 16487.7578, Validation Loss: 19850.0312\n",
      "Epoch [3530/5000], Training Loss: 16473.1504, Validation Loss: 19841.5117\n",
      "Epoch [3540/5000], Training Loss: 16458.5000, Validation Loss: 19832.1738\n",
      "Epoch [3550/5000], Training Loss: 16443.7734, Validation Loss: 19823.7949\n",
      "Epoch [3560/5000], Training Loss: 16429.0742, Validation Loss: 19815.3066\n",
      "Epoch [3570/5000], Training Loss: 16414.5938, Validation Loss: 19807.0410\n",
      "Epoch [3580/5000], Training Loss: 16400.1602, Validation Loss: 19799.2090\n",
      "Epoch [3590/5000], Training Loss: 16386.0898, Validation Loss: 19792.2969\n",
      "Epoch [3600/5000], Training Loss: 16372.0068, Validation Loss: 19785.6484\n",
      "Epoch [3610/5000], Training Loss: 16357.8789, Validation Loss: 19779.4277\n",
      "Epoch [3620/5000], Training Loss: 16343.8867, Validation Loss: 19773.9492\n",
      "Epoch [3630/5000], Training Loss: 16330.1436, Validation Loss: 19767.7871\n",
      "Epoch [3640/5000], Training Loss: 16316.5771, Validation Loss: 19760.2070\n",
      "Epoch [3650/5000], Training Loss: 16303.2344, Validation Loss: 19753.5879\n",
      "Epoch [3660/5000], Training Loss: 16289.8369, Validation Loss: 19746.7305\n",
      "Epoch [3670/5000], Training Loss: 16276.4727, Validation Loss: 19740.0879\n",
      "Epoch [3680/5000], Training Loss: 16263.0654, Validation Loss: 19731.1992\n",
      "Epoch [3690/5000], Training Loss: 16249.5635, Validation Loss: 19723.5312\n",
      "Epoch [3700/5000], Training Loss: 16236.0381, Validation Loss: 19714.0957\n",
      "Epoch [3710/5000], Training Loss: 16222.5088, Validation Loss: 19705.8320\n",
      "Epoch [3720/5000], Training Loss: 16209.1914, Validation Loss: 19696.5547\n",
      "Epoch [3730/5000], Training Loss: 16196.1973, Validation Loss: 19687.6992\n",
      "Epoch [3740/5000], Training Loss: 16183.2607, Validation Loss: 19678.7715\n",
      "Epoch [3750/5000], Training Loss: 16170.6406, Validation Loss: 19670.9355\n",
      "Epoch [3760/5000], Training Loss: 16158.1680, Validation Loss: 19663.2441\n",
      "Epoch [3770/5000], Training Loss: 16145.7051, Validation Loss: 19655.1914\n",
      "Epoch [3780/5000], Training Loss: 16133.3867, Validation Loss: 19647.1660\n",
      "Epoch [3790/5000], Training Loss: 16121.1562, Validation Loss: 19640.2070\n",
      "Epoch [3800/5000], Training Loss: 16109.0205, Validation Loss: 19634.0098\n",
      "Epoch [3810/5000], Training Loss: 16096.8936, Validation Loss: 19626.4492\n",
      "Epoch [3820/5000], Training Loss: 16084.8047, Validation Loss: 19620.3867\n",
      "Epoch [3830/5000], Training Loss: 16072.7158, Validation Loss: 19615.5195\n",
      "Epoch [3840/5000], Training Loss: 16060.6611, Validation Loss: 19611.2207\n",
      "Epoch [3850/5000], Training Loss: 16048.7861, Validation Loss: 19607.9785\n",
      "Epoch [3860/5000], Training Loss: 16036.9844, Validation Loss: 19603.4922\n",
      "Epoch [3870/5000], Training Loss: 16025.3633, Validation Loss: 19600.2324\n",
      "Epoch [3880/5000], Training Loss: 16013.8027, Validation Loss: 19595.9707\n",
      "Epoch [3890/5000], Training Loss: 16002.2461, Validation Loss: 19591.4336\n",
      "Epoch [3900/5000], Training Loss: 15990.6914, Validation Loss: 19586.5391\n",
      "Epoch [3910/5000], Training Loss: 15979.2314, Validation Loss: 19582.4902\n",
      "Epoch [3920/5000], Training Loss: 15967.9141, Validation Loss: 19577.6602\n",
      "Epoch [3930/5000], Training Loss: 15956.6836, Validation Loss: 19572.1738\n",
      "Epoch [3940/5000], Training Loss: 15945.4092, Validation Loss: 19567.2617\n",
      "Epoch [3950/5000], Training Loss: 15934.1748, Validation Loss: 19562.9766\n",
      "Epoch [3960/5000], Training Loss: 15922.8857, Validation Loss: 19559.5625\n",
      "Epoch [3970/5000], Training Loss: 15911.7051, Validation Loss: 19555.6191\n",
      "Epoch [3980/5000], Training Loss: 15900.7539, Validation Loss: 19551.3008\n",
      "Epoch [3990/5000], Training Loss: 15890.1318, Validation Loss: 19546.7793\n",
      "Epoch [4000/5000], Training Loss: 15879.7568, Validation Loss: 19542.3203\n",
      "Epoch [4010/5000], Training Loss: 15869.3301, Validation Loss: 19536.8125\n",
      "Epoch [4020/5000], Training Loss: 15859.1768, Validation Loss: 19532.0762\n",
      "Epoch [4030/5000], Training Loss: 15849.2881, Validation Loss: 19528.1152\n",
      "Epoch [4040/5000], Training Loss: 15839.4795, Validation Loss: 19523.5312\n",
      "Epoch [4050/5000], Training Loss: 15829.6885, Validation Loss: 19519.3203\n",
      "Epoch [4060/5000], Training Loss: 15819.9385, Validation Loss: 19515.7637\n",
      "Epoch [4070/5000], Training Loss: 15810.3730, Validation Loss: 19512.6914\n",
      "Epoch [4080/5000], Training Loss: 15800.6680, Validation Loss: 19508.1816\n",
      "Epoch [4090/5000], Training Loss: 15791.1709, Validation Loss: 19504.2754\n",
      "Epoch [4100/5000], Training Loss: 15781.6729, Validation Loss: 19500.5742\n",
      "Epoch [4110/5000], Training Loss: 15772.0908, Validation Loss: 19496.4355\n",
      "Epoch [4120/5000], Training Loss: 15762.5244, Validation Loss: 19492.1309\n",
      "Epoch [4130/5000], Training Loss: 15753.0801, Validation Loss: 19488.0957\n",
      "Epoch [4140/5000], Training Loss: 15743.5137, Validation Loss: 19483.3105\n",
      "Epoch [4150/5000], Training Loss: 15734.1201, Validation Loss: 19478.0215\n",
      "Epoch [4160/5000], Training Loss: 15724.8340, Validation Loss: 19472.5078\n",
      "Epoch [4170/5000], Training Loss: 15715.4209, Validation Loss: 19466.6738\n",
      "Epoch [4180/5000], Training Loss: 15706.1572, Validation Loss: 19460.9980\n",
      "Epoch [4190/5000], Training Loss: 15696.9316, Validation Loss: 19456.0273\n",
      "Epoch [4200/5000], Training Loss: 15687.7178, Validation Loss: 19450.7832\n",
      "Epoch [4210/5000], Training Loss: 15678.6230, Validation Loss: 19445.5762\n",
      "Epoch [4220/5000], Training Loss: 15669.4385, Validation Loss: 19438.7832\n",
      "Epoch [4230/5000], Training Loss: 15660.2705, Validation Loss: 19431.8574\n",
      "Epoch [4240/5000], Training Loss: 15651.1211, Validation Loss: 19426.3418\n",
      "Epoch [4250/5000], Training Loss: 15641.8594, Validation Loss: 19420.3047\n",
      "Epoch [4260/5000], Training Loss: 15632.5957, Validation Loss: 19413.9805\n",
      "Epoch [4270/5000], Training Loss: 15623.3115, Validation Loss: 19407.9121\n",
      "Epoch [4280/5000], Training Loss: 15614.1270, Validation Loss: 19401.8945\n",
      "Epoch [4290/5000], Training Loss: 15604.7246, Validation Loss: 19395.9004\n",
      "Epoch [4300/5000], Training Loss: 15595.3936, Validation Loss: 19390.1484\n",
      "Epoch [4310/5000], Training Loss: 15586.2793, Validation Loss: 19382.5762\n",
      "Epoch [4320/5000], Training Loss: 15576.8027, Validation Loss: 19376.9141\n",
      "Epoch [4330/5000], Training Loss: 15567.5293, Validation Loss: 19370.5547\n",
      "Epoch [4340/5000], Training Loss: 15558.5156, Validation Loss: 19364.5078\n",
      "Epoch [4350/5000], Training Loss: 15549.4980, Validation Loss: 19359.1250\n",
      "Epoch [4360/5000], Training Loss: 15540.6025, Validation Loss: 19352.5098\n",
      "Epoch [4370/5000], Training Loss: 15531.6064, Validation Loss: 19346.1328\n",
      "Epoch [4380/5000], Training Loss: 15522.6680, Validation Loss: 19340.6250\n",
      "Epoch [4390/5000], Training Loss: 15513.7686, Validation Loss: 19335.9297\n",
      "Epoch [4400/5000], Training Loss: 15504.9141, Validation Loss: 19328.7344\n",
      "Epoch [4410/5000], Training Loss: 15496.1709, Validation Loss: 19322.2715\n",
      "Epoch [4420/5000], Training Loss: 15487.5391, Validation Loss: 19315.3535\n",
      "Epoch [4430/5000], Training Loss: 15479.0391, Validation Loss: 19307.9062\n",
      "Epoch [4440/5000], Training Loss: 15470.5381, Validation Loss: 19299.9336\n",
      "Epoch [4450/5000], Training Loss: 15462.2451, Validation Loss: 19291.9375\n",
      "Epoch [4460/5000], Training Loss: 15453.6729, Validation Loss: 19284.0352\n",
      "Epoch [4470/5000], Training Loss: 15445.4004, Validation Loss: 19277.1309\n",
      "Epoch [4480/5000], Training Loss: 15437.1455, Validation Loss: 19270.2832\n",
      "Epoch [4490/5000], Training Loss: 15429.0449, Validation Loss: 19262.4512\n",
      "Epoch [4500/5000], Training Loss: 15420.7451, Validation Loss: 19256.5801\n",
      "Epoch [4510/5000], Training Loss: 15412.5527, Validation Loss: 19250.0371\n",
      "Epoch [4520/5000], Training Loss: 15404.4609, Validation Loss: 19242.0352\n",
      "Epoch [4530/5000], Training Loss: 15396.3164, Validation Loss: 19234.4121\n",
      "Epoch [4540/5000], Training Loss: 15388.2949, Validation Loss: 19226.9297\n",
      "Epoch [4550/5000], Training Loss: 15380.4365, Validation Loss: 19220.3320\n",
      "Epoch [4560/5000], Training Loss: 15372.3457, Validation Loss: 19213.5391\n",
      "Epoch [4570/5000], Training Loss: 15364.4775, Validation Loss: 19208.1270\n",
      "Epoch [4580/5000], Training Loss: 15356.7500, Validation Loss: 19202.1074\n",
      "Epoch [4590/5000], Training Loss: 15348.9453, Validation Loss: 19194.3242\n",
      "Epoch [4600/5000], Training Loss: 15341.2090, Validation Loss: 19188.7070\n",
      "Epoch [4610/5000], Training Loss: 15333.4316, Validation Loss: 19183.8633\n",
      "Epoch [4620/5000], Training Loss: 15325.8838, Validation Loss: 19178.3672\n",
      "Epoch [4630/5000], Training Loss: 15318.0996, Validation Loss: 19172.8906\n",
      "Epoch [4640/5000], Training Loss: 15310.4346, Validation Loss: 19166.1133\n",
      "Epoch [4650/5000], Training Loss: 15302.9482, Validation Loss: 19161.1758\n",
      "Epoch [4660/5000], Training Loss: 15295.6025, Validation Loss: 19157.2715\n",
      "Epoch [4670/5000], Training Loss: 15288.4688, Validation Loss: 19153.1738\n",
      "Epoch [4680/5000], Training Loss: 15281.0293, Validation Loss: 19148.6562\n",
      "Epoch [4690/5000], Training Loss: 15273.8438, Validation Loss: 19146.1582\n",
      "Epoch [4700/5000], Training Loss: 15266.7158, Validation Loss: 19141.7930\n",
      "Epoch [4710/5000], Training Loss: 15259.3320, Validation Loss: 19137.6797\n",
      "Epoch [4720/5000], Training Loss: 15252.0430, Validation Loss: 19133.9375\n",
      "Epoch [4730/5000], Training Loss: 15244.7295, Validation Loss: 19130.6270\n",
      "Epoch [4740/5000], Training Loss: 15237.6230, Validation Loss: 19125.5684\n",
      "Epoch [4750/5000], Training Loss: 15230.3682, Validation Loss: 19120.9375\n",
      "Epoch [4760/5000], Training Loss: 15223.1064, Validation Loss: 19114.9238\n",
      "Epoch [4770/5000], Training Loss: 15216.0186, Validation Loss: 19108.8965\n",
      "Epoch [4780/5000], Training Loss: 15209.0176, Validation Loss: 19104.6172\n",
      "Epoch [4790/5000], Training Loss: 15201.8975, Validation Loss: 19099.3027\n",
      "Epoch [4800/5000], Training Loss: 15195.1729, Validation Loss: 19094.6367\n",
      "Epoch [4810/5000], Training Loss: 15188.4277, Validation Loss: 19090.3398\n",
      "Epoch [4820/5000], Training Loss: 15181.6797, Validation Loss: 19086.4043\n",
      "Epoch [4830/5000], Training Loss: 15175.2451, Validation Loss: 19081.5645\n",
      "Epoch [4840/5000], Training Loss: 15168.8506, Validation Loss: 19076.9004\n",
      "Epoch [4850/5000], Training Loss: 15162.4453, Validation Loss: 19075.0312\n",
      "Epoch [4860/5000], Training Loss: 15156.1113, Validation Loss: 19069.7598\n",
      "Epoch [4870/5000], Training Loss: 15150.0928, Validation Loss: 19067.8398\n",
      "Epoch [4880/5000], Training Loss: 15144.0137, Validation Loss: 19064.5117\n",
      "Epoch [4890/5000], Training Loss: 15137.9111, Validation Loss: 19061.9219\n",
      "Epoch [4900/5000], Training Loss: 15131.9658, Validation Loss: 19058.8223\n",
      "Epoch [4910/5000], Training Loss: 15125.7979, Validation Loss: 19057.7617\n",
      "Epoch [4920/5000], Training Loss: 15119.7607, Validation Loss: 19053.3301\n",
      "Epoch [4930/5000], Training Loss: 15113.6455, Validation Loss: 19051.7188\n",
      "Epoch [4940/5000], Training Loss: 15107.7002, Validation Loss: 19048.9805\n",
      "Epoch [4950/5000], Training Loss: 15101.5449, Validation Loss: 19044.5879\n",
      "Epoch [4960/5000], Training Loss: 15095.5527, Validation Loss: 19042.9277\n",
      "Epoch [4970/5000], Training Loss: 15089.5547, Validation Loss: 19039.9219\n",
      "Epoch [4980/5000], Training Loss: 15083.6934, Validation Loss: 19036.5176\n",
      "Epoch [4990/5000], Training Loss: 15077.5938, Validation Loss: 19032.5371\n",
      "Epoch [5000/5000], Training Loss: 15071.5459, Validation Loss: 19030.0703\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Parameters\n",
    "num_epochs = 5000\n",
    "\n",
    "# Tracking losses for visualization\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    # Forward pass on the entire training set\n",
    "    predictions = model(X_train_tensor)\n",
    "    loss = criterion(predictions, y_train_tensor)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Record training loss\n",
    "    train_loss = loss.item()\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_predictions = model(X_val_tensor)\n",
    "        val_loss = criterion(val_predictions, y_val_tensor).item()\n",
    "        val_losses.append(val_loss)\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "# Visualizing the training and validation loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     test_predictions = model(X_test_tensor)\n",
    "#     test_loss = criterion(test_predictions, y_test_tensor)\n",
    "#     print(f'Test Loss: {test_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#test data processing\n",
    "raw_test_data = pd.read_csv('./data/test.csv')\n",
    "test_data = raw_test_data.drop(columns=columns_to_drop, axis=1)\n",
    "numeric_columns = [x for x in numeric_columns if x != \"SalePrice\"]\n",
    "test_data[numeric_columns] = test_data[numeric_columns].fillna(data[numeric_columns].median())\n",
    "\n",
    "# Fill categorical columns with the mode value\n",
    "# data[categorical_columns] = data[categorical_columns].apply(lambda x: x.fillna(x.mode()[0]))\n",
    "test_data[categorical_cols] = categorical_imputer.fit_transform(test_data[categorical_cols])\n",
    "\n",
    "# Encode categorical variables\n",
    "\n",
    "# for col in categorical_cols:|\n",
    "#     unseen_labels = set(test_data[col]) - set(encoder.classes_)\n",
    "#     # Replace unseen labels with 'unknown' (or another special category)\n",
    "#     test_data[col] = test_data[col].apply(lambda x: 'unknown' if x in unseen_labels else x)\n",
    "\n",
    "#     # Optionally, add 'unknown' to the encoder's classes if needed\n",
    "#     encoder.classes_ = np.append(encoder.classes_, 'unknown')\n",
    "\n",
    "#     # Transform the test data using the same encoder\n",
    "#     test_data[col] = encoder.transform(test_data[col])\n",
    "#         # data[col] = encoder.transform(data[col])\n",
    "encoded_categorical_cols = pd.DataFrame(encoder.transform(test_data[categorical_cols]),index=test_data.index)\n",
    "encoded_categorical_cols.columns = encoder.get_feature_names_out(categorical_cols)\n",
    "test_data = test_data.drop(columns=categorical_cols, axis=1).join(encoded_categorical_cols)\n",
    "\n",
    "# Feature scaling\n",
    "test_data[numeric_columns] = scaler.fit_transform(test_data[numeric_columns])\n",
    "\n",
    "# Separate features and target\n",
    "X_test = test_data.drop(['Id'], axis=1)  # Replace 'target_column' with the actual target column name\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[126496.9844],\n",
      "        [157857.1562],\n",
      "        [191983.2812],\n",
      "        [206977.1094],\n",
      "        [192607.9688]])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    predictions = model(X_test_tensor)\n",
    "    print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'Id': raw_test_data['Id'].astype('int32').values,  # The ID column from the test set\n",
    "    'SalePrice': predictions.squeeze()  # The predicted values\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
